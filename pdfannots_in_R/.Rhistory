# To write out the full text, use writeLines()
class(docs[1])
writeLines(as.character(docs[1]))
stripWhitespace("/test/testoutput.txt")
## For details about documents in the corpus, use the inspect(docs) command.
inspect(docs[1])
writeLines(as.character(docs[1])) # Check to see if it worked.
for (j in seq(docs)) {
docs[[j]] <- gsub( "\t"," ", docs[[j]])
docs[[j]] <- gsub( " +"," ", docs[[j]])
}
writeLines(as.character(docs[1])) # Check to see if it worked.
system("python pdfannots.py -p -o testoutput.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
library(reticulate)
system("python pdfannots.py -p -o testoutput.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
system("python pdfannots.py --help") #Brings up the help menu
library(reticulate)
system("python pdfannots.py -p -o testoutput.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
system("python pdfannots.py -p -o testoutput.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
system("python pdfannots.py -p -o testoutput.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
system("python pdfannots.py -p -o testoutput.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
system("python pdfannots.py -p -o testoutput.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
system("python pdfannots.py --help") #Brings up the help menu
library(tm)
## Get R packages for text mining
library(tm)
library("reticulate")
#From here we will have to run the script using this line:
##The input/ can be any .pdf file with annotations
### the -p flag shows the progress of the script in the console. the -o output.txt makes a .txt file with the output in it
system("python pdfannots.py -p -o output.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
## First we will have to get the data. Please move the output.txt into the messytxts folder at first and then do the following:
cname <- file.path("./messytxts/")
cname
dir(cname)
## Get R packages for text mining
library(tm)
## Lets load texts to R
docs <- VCorpus(DirSource(cname))
summary(docs)
## For details about documents in the corpus, use the inspect(docs) command.
inspect(docs[1])
# To write out the full text, use writeLines()
class(docs[1])
writeLines(as.character(docs[1]))
writeLines(as.character(docs[1]))
#This is the regular expression section to use if there are a lot of \t in the plain text file from writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub( "\t "," ", docs[[j]])
docs[[j]] <- gsub( "\t"," ", docs[[j]])
}
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#This command saves the changes to the documents
docs <- tm_map(docs, PlainTextDocument)
docs <- tm_map(docs, stripWhitespace)
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#From here we will have to run the script using this line:
##The input/ can be any .pdf file with annotations
### the -p flag shows the progress of the script in the console. the -o output.txt makes a .txt file with the output in it
system("python pdfannots.py -p -o output.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
## First we will have to get the data. Please move the output.txt into the messytxts folder at first and then do the following:
cname <- file.path("./messytxts/")
cname
dir(cname)
## Get R packages for text mining
library(tm)
## Lets load texts to R
docs <- VCorpus(DirSource(cname))
summary(docs)
## For details about documents in the corpus, use the inspect(docs) command.
inspect(docs[1])
# To write out the full text, use writeLines()
class(docs[1])
writeLines(as.character(docs[1]))
docs <- tm_map(docs, stripWhitespace)
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#This command saves the changes to the documents
docs <- tm_map(docs, PlainTextDocument)
View(docs)
(docs, PlainTextDocument)
#Removes whitespaces - which usually does the trick for the output of the script
docs <- tm_map(docs, stripWhitespace)
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#This command saves the changes to the documents
docs <- tm_map(docs, PlainTextDocument)
table(docs)
data.frame(docs)
writeCorpus(/"Result/")
writeCorpus("Result/")
getwd()
writeCorpus(ovid)
#This command saves the changes to the documents
docs <- tm_map(docs, PlainTextDocument)
library("reticulate")
#From here we will have to run the script using this line:
##The input/ can be any .pdf file with annotations
### the -p flag shows the progress of the script in the console. the -o output.txt makes a .txt file with the output in it
system("python pdfannots.py -p -o output.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
## First we will have to get the data. Please move the output.txt into the messytxts folder at first and then do the following:
cname <- file.path("./messytxts/")
cname
dir(cname)
## Get R packages for text mining
library(tm)
## Lets load texts to R
docs <- VCorpus(DirSource(cname))
summary(docs)
## For details about documents in the corpus, use the inspect(docs) command.
inspect(docs[1])
# To write out the full text, use writeLines()
class(docs[1])
writeLines(as.character(docs[1]))
#Removes whitespaces - which usually does the trick for the output of the script
docs <- tm_map(docs, stripWhitespace)
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#This command saves the changes to the documents
docs <- tm_map(docs, PlainTextDocument)
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#From here we will have to run the script using this line:
##The input/ can be any .pdf file with annotations
### the -p flag shows the progress of the script in the console. the -o output.txt makes a .txt file with the output in it
system("python pdfannots.py -p -o output.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
## First we will have to get the data. Please move the output.txt into the messytxts folder at first
file.copy("output.txt", "messytxts/output.txt")
#Then delete the old output.txt file
unlink("output.txt")
#Now we will do some textmining - this is to get the data
cname <- file.path("./messytxts/")
cname
dir(cname)
## Get R packages for text mining
library(tm)
## Lets load texts to R
docs <- VCorpus(DirSource(cname))
summary(docs)
## For details about documents in the corpus, use the inspect(docs) command.
inspect(docs[1])
# To write out the full text, use writeLines()
class(docs[1])
writeLines(as.character(docs[1]))
docs[[j]] <- gsub( "[:blank:]"," ", docs[[j]])
docs[[j]] <- gsub( "[:blank:]"," ", docs[[j]])
docs[[j]] <- gsub( "[:blank:]"," ", docs[[j]])
#This is the regular expression section to use if there are a lot of \t in the plain text file from writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub( "[:blank:]"," ", docs[[j]])
}
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#This command saves the changes to the documents
docs <- tm_map(docs, PlainTextDocument)
#From here we will have to run the script using this line:
##The input/ can be any .pdf file with annotations
### the -p flag shows the progress of the script in the console. the -o output.txt makes a .txt file with the output in it
system("python pdfannots.py -p -o output.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
## First we will have to get the data. Please copy the output.txt into the messytxts folder at first
file.copy("output.txt", "messytxts/output.txt")
## First we will have to get the data. Please copy the output.txt into the messytxts folder at first
file.copy("output.txt", "messytxts/output.txt")
#Then delete the old output.txt file
unlink("output.txt")
#Now we will do some textmining - this is to get the data
cname <- file.path("./messytxts/")
cname
dir(cname)
## Get R packages for text mining
library(tm)
## Lets load texts to R
docs <- VCorpus(DirSource(cname))
summary(docs)
View(docs)
list(docs)
## For details about documents in the corpus, use the inspect(docs) command.
inspect(docs[1])
# To write out the full text, use writeLines()
class(docs[1])
writeLines(as.character(docs[1]))
#This is the regular expression section to use if there are a lot of \t in the plain text file from writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub( "\s"," ", docs[[j]])
}
#This is the regular expression section to use if there are a lot of \t in the plain text file from writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub( "\s"," ", docs[[j]])
}
#This is the regular expression section to use if there are a lot of \t in the plain text file from writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub( "\t"," ", docs[[j]])
}
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#This is the regular expression section to use if there are a lot of \t in the plain text file from writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub( "\t"," ", docs[[j]])
docs[[j]] <- gsub( "", "","\t", docs[[j]])
}
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#From here we will have to run the script using this line:
##The input/ can be any .pdf file with annotations
### the -p flag shows the progress of the script in the console. the -o output.txt makes a .txt file with the output in it
system("python pdfannots.py -p -o output.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
## First we will have to get the data. Please copy the output.txt into the messytxts folder at first
file.copy("output.txt", "messytxts/output.txt")
#Then delete the old output.txt file
unlink("output.txt")
#Now we will do some textmining - this is to get the data
cname <- file.path("./messytxts/")
cname
dir(cname)
## For details about documents in the corpus, use the inspect(docs) command.
inspect(docs[1])
## Lets load texts to R
docs <- VCorpus(DirSource(cname))
## Get R packages for text mining
library(tm)
#Now we will do some textmining - this is to get the data
cname <- file.path("./messytxts/")
cname
dir(cname)
## Get R packages for text mining
library(tm)
## Lets load texts to R
docs <- VCorpus(DirSource(cname))
summary(docs)
## For details about documents in the corpus, use the inspect(docs) command.
inspect(docs[1])
# To write out the full text, use writeLines()
class(docs[1])
writeLines(as.character(docs[1]))
#Removes whitespaces - which usually does the trick for the output of the script
docs <- tm_map(docs, stripWhitespace)
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#This is the regular expression section to use if there are a lot of \t in the plain text file from writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub("\t"," ", docs[[j]])
docs[[j]] <- gsub("", "","\n", docs[[j]])
}
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#From here we will have to run the script using this line:
##The input/ can be any .pdf file with annotations
### the -p flag shows the progress of the script in the console. the -o output.txt makes a .txt file with the output in it
system("python pdfannots.py -p -o output.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
## First we will have to get the data. Please copy the output.txt into the messytxts folder at first
file.copy("output.txt", "messytxts/output.txt")
#Then delete the old output.txt file
unlink("output.txt")
#Now we will do some textmining - this is to get the data
cname <- file.path("./messytxts/")
cname
dir(cname)
## Get R packages for text mining
library(tm)
## Lets load texts to R
docs <- VCorpus(DirSource(cname))
summary(docs)
## For details about documents in the corpus, use the inspect(docs) command.
inspect(docs[1])
# To write out the full text, use writeLines()
class(docs[1])
writeLines(as.character(docs[1]))
#Removes whitespaces - which usually does the trick for the output of the script
docs <- tm_map(docs, stripWhitespace)
writeLines(as.character(docs[1]))
#From here we will have to run the script using this line:
##The input/ can be any .pdf file with annotations
### the -p flag shows the progress of the script in the console. the -o output.txt makes a .txt file with the output in it
system("python pdfannots.py -p -o output.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
## First we will have to get the data. Please copy the output.txt into the messytxts folder at first
file.copy("output.txt", "messytxts/output.txt")
#Then delete the old output.txt file
unlink("output.txt")
#Now we will do some textmining - this is to get the data
cname <- file.path("./messytxts/")
cname
dir(cname)
## Get R packages for text mining
library(tm)
## Lets load texts to R
docs <- VCorpus(DirSource(cname))
summary(docs)
## For details about documents in the corpus, use the inspect(docs) command.
inspect(docs[1])
# To write out the full text, use writeLines()
class(docs[1])
writeLines(as.character(docs[1]))
#This is the regular expression section to use if there are a lot of \t in the plain text file from writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub("", "","\n", docs[[j]])
docs[[j]] <- gsub("\t"," ", docs[[j]])
}
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#From here we will have to run the script using this line:
##The input/ can be any .pdf file with annotations
### the -p flag shows the progress of the script in the console. the -o output.txt makes a .txt file with the output in it
system("python pdfannots.py -p -o output.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
## First we will have to get the data. Please copy the output.txt into the messytxts folder at first
file.copy("output.txt", "messytxts/output.txt")
#Then delete the old output.txt file
unlink("output.txt")
#Now we will do some textmining - this is to get the data
cname <- file.path("./messytxts/")
cname
dir(cname)
## Get R packages for text mining
library(tm)
## Lets load texts to R
docs <- VCorpus(DirSource(cname))
summary(docs)
## For details about documents in the corpus, use the inspect(docs) command.
inspect(docs[1])
# To write out the full text, use writeLines()
class(docs[1])
writeLines(as.character(docs[1]))
#This is the regular expression section to use if there are a lot of \t in the plain text file from writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub("\t"," ", docs[[j]])
}
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#This is the regular expression section to use if there are a lot of \t in the plain text file from writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub("\t"," ", docs[[j]])
docs[[j]] <- gsub("\", ","\n", docs[[j]])
}
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#This is the regular expression section to use if there are a lot of \t in the plain text file from writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub("\t"," ", docs[[j]])
docs[[j]] <- gsub("\", "," ", docs[[j]])
}
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
View(j)
docs[[j]] <- gsub("\", ","", docs[[j]])
#This command saves the changes to the documents
docs <- tm_map(docs, PlainTextDocument)
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
writeCorpus("messytxts/")
writeCorpus("messytxts/output.txt")
writeCorpus("messytxts/", "output2.txt")
#From here we will have to run the script using this line:
##The input/ can be any .pdf file with annotations
### the -p flag shows the progress of the script in the console. the -o output.txt makes a .txt file with the output in it
system("python pdfannots.py -p -o output.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
## First we will have to get the data. Please copy the output.txt into the messytxts folder at first
file.copy("output.txt", "messytxts/output.txt")
#Then delete the old output.txt file
unlink("output.txt")
#Now we will do some textmining - this is to get the data
cname <- file.path("./messytxts/")
cname
dir(cname)
## Get R packages for text mining
library(tm)
## Lets load texts to R
docs <- VCorpus(DirSource(cname))
summary(docs)
## For details about documents in the corpus, use the inspect(docs) command.
inspect(docs[1])
# To write out the full text, use writeLines()
class(docs[1])
writeLines(as.character(docs[1]))
#This is the regular expression section to use if there are a lot of \t in the plain text file from writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub("\t"," ", docs[[j]])
docs[[j]] <- gsub("(", ")","\n", docs[[j]])
}
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
docs[[j]] <- gsub("*","\n", docs[[j]])
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#From here we will have to run the script using this line:
##The input/ can be any .pdf file with annotations
### the -p flag shows the progress of the script in the console. the -o output.txt makes a .txt file with the output in it
system("python pdfannots.py -p -o output.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
## First we will have to get the data. Please copy the output.txt into the messytxts folder at first
file.copy("output.txt", "messytxts/output.txt")
#Then delete the old output.txt file
unlink("output.txt")
#Now we will do some textmining - this is to get the data
cname <- file.path("./messytxts/")
cname
dir(cname)
## Get R packages for text mining
library(tm)
## Lets load texts to R
docs <- VCorpus(DirSource(cname))
summary(docs)
## For details about documents in the corpus, use the inspect(docs) command.
inspect(docs[1])
# To write out the full text, use writeLines()
class(docs[1])
writeLines(as.character(docs[1]))
docs[[j]] <- gsub("\t"," ", docs[[j]])
docs[[j]] <- gsub("\t"," ", docs[[j]])
#This is the regular expression section to use if there are a lot of \t in the plain text file from writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub("\t"," ", docs[[j]])
}
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#This command saves the changes to the documents
docs <- tm_map(docs, PlainTextDocument)
for (j in seq(docs)) {
docs[[j]] <- gsub(" +"," ", docs[[j]])
}
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#From here we will have to run the script using this line:
##The input/ can be any .pdf file with annotations
### the -p flag shows the progress of the script in the console. the -o output.txt makes a .txt file with the output in it
system("python pdfannots.py -p -o output.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
## First we will have to get the data. Please copy the output.txt into the messytxts folder at first
file.copy("output.txt", "messytxts/output.txt")
#Cleaning the result with stringr from tidyverse
#Loading tidyverse
library(tidyverse)
text <- "messytxts/output.txt"
str_replace_all(text, "\\s+", " ")
str_trim(text)
#From here we will have to run the script using this line:
##The input/ can be any .pdf file with annotations
### the -p flag shows the progress of the script in the console. the -o output.txt makes a .txt file with the output in it
system("python pdfannots.py -p -o output.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
#From here we will have to do some cleaning of the final result. The .txt file can have some huge white spaces which can be removed using regular expressions
## First we will have to get the data. Please copy the output.txt into the messytxts folder at first
file.copy("output.txt", "messytxts/output.txt")
#Then delete the old output.txt file
unlink("output.txt")
#Now we will do some textmining - this is to get the data
cname <- file.path("./messytxts/")
cname
dir(cname)
## Get R packages for text mining
library(tm)
## Lets load texts to R
docs <- VCorpus(DirSource(cname))
summary(docs)
## For details about documents in the corpus, use the inspect(docs) command.
inspect(docs[1])
# To write out the full text, use writeLines()
class(docs[1])
writeLines(as.character(docs[1]))
#This is the regular expression section to use if there are a lot of \t in the plain text file from writeLines(as.character(docs[1]))
for (j in seq(docs)) {
docs[[j]] <- gsub("\t"," ", docs[[j]])
}
#This command saves the changes to the documents
docs <- tm_map(docs, PlainTextDocument)
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
writeCorpus(output, path = "./Result/", filenames = NULL)
writeCorpus(docs, path = "./Result/", filenames = NULL)
#From here we will have to run the script using this line:
##The input/ can be any .pdf file with annotations
### the -p flag shows the progress of the script in the console. the -o output.txt makes a .txt file with the output in it
system("python pdfannots.py -p -o output.txt input/a_history_of_medieval_heresy_and_inquisition.pdf")
#From here we will have to do some cleaning of the final result. The .txt file can have some huge white spaces which can be removed using regular expressions
## First we will have to get the data. Please copy the output.txt into the messytxts folder at first
file.copy("output.txt", "messytxts/output.txt")
#Then delete the old output.txt file
unlink("output.txt")
#Now we will do some textmining - this is to get the data
cname <- file.path("./messytxts/")
cname
dir(cname)
## Get R packages for text mining
library(tm)
## Lets load texts to R
docs <- VCorpus(DirSource(cname))
summary(docs)
## For details about documents in the corpus, use the inspect(docs) command.
inspect(docs[1])
# To write out the full text, use writeLines()
class(docs[1])
writeLines(as.character(docs[1]))
#This is the regular expression section to use if there are a lot of \t in the plain text file from writeLines(as.character(docs[1]))
###I need to make a regular expression, that substitutes ", " with a newline
### Can the tm-package make an output file as well, instead of just making a change to the corpus
for (j in seq(docs)) {
docs[[j]] <- gsub("\t"," ", docs[[j]])
docs[[j]] <- gsub(" +"," ", docs[[j]])
}
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
#This command saves the changes to the documents
docs <- tm_map(docs, PlainTextDocument)
#This command exports the clean text to the Results folder
writeCorpus(docs, path = "./Result/", filenames = heresy_notes) #THIS WORKS - NEEDS A FILENAME
#This command exports the clean text to the Results folder
writeCorpus(docs, path = "./Result/", filenames = NULL) #THIS WORKS - NEEDS A FILENAME
#To show the file (or one of the files) afterwards use this command again:
writeLines(as.character(docs[1]))
